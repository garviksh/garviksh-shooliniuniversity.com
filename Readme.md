# garviksh-shooliniuniversity.com
artificial intelligence (University)
information regarding the webscraping 
Web Scraping - (also termed Screen Scraping, Web Data Extraction, Web Harvesting etc.) is a technique employed to extract large amounts of data from websites whereby the data is extracted and saved to a local file in your computer or to a database in table (spreadsheet) format.

web scraping involves three steps: 

first, we send a GET request to the server and we will receive a response in a form of web content. 
Next, we parse the HTML code of a web site following a tree structure path. 
Finally, we use the python library to search for the parse tree.

web scraping looks good on paper but actually more complex in practice. We need coding to get the data we want, which makes it the privilege of who’s master of programming. As an alternative, there are web scraping tools automating web data extraction at fingertips. 

 

A web scraping tool will load the URLs given by the users and render the entire website. As a result, you can extract any web data with simple point-and-click and file in a feasible format into your computer without coding. 

 

For example, you might want to extract posts and comments from Twitter. All you have to do is to paste the URL to the scraper, select desired posts and comments and execute. Therefore, it saves time and efforts from the mundane work of copy-and-paste. 

 

How did web scraping all start?
Though to many people, it sounds like a brand-new concept, the history of the web scraping can be dated back to the time when the World Wide Web was born.

 

At the very beginning, the Internet was even unsearchable. Before search engines were developed, the Internet was just a collection of File Transfer Protocol (FTP) sites in which users would navigate to find specific shared files. To find and organize distributed data available on the Internet, people created a specific automated program, known as the web crawler/bot today, to fetch all pages on the Internet and then copy all content into databases for indexing. 

 

Then the Internet grows, eventually becoming the home to millions of web pages that contain a wealth of data in multiple forms, including texts, images, videos, and audios. It turns into an open data source.

 

As the data source became incredibly rich and easily searchable, people started to find it simple to seek the information they want, which often spread across a large number of websites, but the problem occurred when they wanted to get data from the Internet—not every website offered download options, and copying by hand was obviously tedious and inefficient.

 

And that’s where web scraping came in. Web scraping is actually powered by web bots/crawlers that function the same way those used in search engines. That is, fetch and copy. The only difference could be the scale. Web scraping focuses on extracting only specific data from certain websites whereas search engines often fetch most of the websites around the Internet
